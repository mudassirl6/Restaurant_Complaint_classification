{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Index</th>\n",
       "      <th>Review</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Cleaned_Name</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "      <th>Review_Days</th>\n",
       "      <th>Response_Days</th>\n",
       "      <th>Predicted_Category</th>\n",
       "      <th>Probabilities</th>\n",
       "      <th>Mapped_Category</th>\n",
       "      <th>Hygiene</th>\n",
       "      <th>Food Quality</th>\n",
       "      <th>Atmosphere</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Service Issue</th>\n",
       "      <th>Positive Review</th>\n",
       "      <th>Food Options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Stop eating at this place, I have visited bang...</td>\n",
       "      <td>stop eating place visited bangalores nd punes ...</td>\n",
       "      <td>pramod kumar</td>\n",
       "      <td>High</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>180</td>\n",
       "      <td>-1</td>\n",
       "      <td>['Quality, taste, or freshness issues with foo...</td>\n",
       "      <td>[0.9965850710868835, 0.9946374893188477, 0.844...</td>\n",
       "      <td>['Food Quality', 'Hygiene', 'Service Issue']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Food 2/5\\nService 2/5\\nAmbience 2/5 …</td>\n",
       "      <td>food service ambience</td>\n",
       "      <td>abhinav deep</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>['Poor customer service or staff behavior', 'Q...</td>\n",
       "      <td>[0.8227755427360535, 0.7571902871131897]</td>\n",
       "      <td>['Service Issue', 'Food Quality']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Idiotic varieties for the price they have char...</td>\n",
       "      <td>idiotic varieties price charged varieties boil...</td>\n",
       "      <td>vijay nammi</td>\n",
       "      <td>High</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>['Quality, taste, or freshness issues with foo...</td>\n",
       "      <td>[0.9860756993293762, 0.98301100730896]</td>\n",
       "      <td>['Food Quality', 'Value for Money']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>I am posting this live now, this is one of the...</td>\n",
       "      <td>posting live one worst places dont visit pathe...</td>\n",
       "      <td>surya ajay</td>\n",
       "      <td>High</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>['Poor customer service or staff behavior', 'Q...</td>\n",
       "      <td>[0.992651641368866, 0.9484805464744568]</td>\n",
       "      <td>['Service Issue', 'Food Quality']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>We are pure vegetarians, I ordered veg biryani...</td>\n",
       "      <td>pure vegetarians ordered veg biryani swiggy go...</td>\n",
       "      <td>sai hithesh</td>\n",
       "      <td>Low</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>180</td>\n",
       "      <td>-1</td>\n",
       "      <td>['Poor customer service or staff behavior', 'C...</td>\n",
       "      <td>[0.9473494291305542, 0.8612152338027954, 0.833...</td>\n",
       "      <td>['Service Issue', 'Value for Money', 'Food Qua...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Index                                             Review  \\\n",
       "0           0      0  Stop eating at this place, I have visited bang...   \n",
       "1           1      1              Food 2/5\\nService 2/5\\nAmbience 2/5 …   \n",
       "2           2      2  Idiotic varieties for the price they have char...   \n",
       "3           3      3  I am posting this live now, this is one of the...   \n",
       "4           4      4  We are pure vegetarians, I ordered veg biryani...   \n",
       "\n",
       "                                      Cleaned_Review  Cleaned_Name Severity  \\\n",
       "0  stop eating place visited bangalores nd punes ...  pramod kumar     High   \n",
       "1                              food service ambience  abhinav deep   Medium   \n",
       "2  idiotic varieties price charged varieties boil...   vijay nammi     High   \n",
       "3  posting live one worst places dont visit pathe...    surya ajay     High   \n",
       "4  pure vegetarians ordered veg biryani swiggy go...   sai hithesh      Low   \n",
       "\n",
       "      Urgency Customer_Satisfaction  Review_Days  Response_Days  \\\n",
       "0      Urgent           No Response          180             -1   \n",
       "1  Non-Urgent     High Satisfaction          365            365   \n",
       "2      Urgent           No Response           30             -1   \n",
       "3      Urgent     High Satisfaction          365            365   \n",
       "4  Non-Urgent           No Response          180             -1   \n",
       "\n",
       "                                  Predicted_Category  \\\n",
       "0  ['Quality, taste, or freshness issues with foo...   \n",
       "1  ['Poor customer service or staff behavior', 'Q...   \n",
       "2  ['Quality, taste, or freshness issues with foo...   \n",
       "3  ['Poor customer service or staff behavior', 'Q...   \n",
       "4  ['Poor customer service or staff behavior', 'C...   \n",
       "\n",
       "                                       Probabilities  \\\n",
       "0  [0.9965850710868835, 0.9946374893188477, 0.844...   \n",
       "1           [0.8227755427360535, 0.7571902871131897]   \n",
       "2             [0.9860756993293762, 0.98301100730896]   \n",
       "3            [0.992651641368866, 0.9484805464744568]   \n",
       "4  [0.9473494291305542, 0.8612152338027954, 0.833...   \n",
       "\n",
       "                                     Mapped_Category  Hygiene  Food Quality  \\\n",
       "0       ['Food Quality', 'Hygiene', 'Service Issue']        1             1   \n",
       "1                  ['Service Issue', 'Food Quality']        0             1   \n",
       "2                ['Food Quality', 'Value for Money']        0             1   \n",
       "3                  ['Service Issue', 'Food Quality']        0             1   \n",
       "4  ['Service Issue', 'Value for Money', 'Food Qua...        0             1   \n",
       "\n",
       "   Atmosphere  Value for Money  Service Issue  Positive Review  Food Options  \n",
       "0           0                0              1                0             0  \n",
       "1           0                0              1                0             0  \n",
       "2           0                1              0                0             0  \n",
       "3           0                0              1                0             0  \n",
       "4           0                1              1                0             0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"abc.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_add = ['Service Issue', 'Food Options', 'Food Quality', 'Atmosphere', 'Value for Money', 'Hygiene', 'Positive Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split Data into Training and Test Sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['Cleaned_Review'], df[categories_to_add], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert Labels to Tensors\n",
    "train_labels = torch.tensor(train_labels.values).float()\n",
    "test_labels = torch.tensor(test_labels.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Custom Dataset Class\n",
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):  # Corrected constructor method name\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):  # Corrected method name\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):  # Corrected method name\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = ReviewDataset(train_encodings, train_labels)\n",
    "test_dataset = ReviewDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load BERT model for classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # Standard binary cross-entropy loss\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion, accumulation_steps=4):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation function\n",
    "# def evaluate(model, test_loader, threshold=0.5):\n",
    "#     model.eval()\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch in test_loader:\n",
    "#             inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "#             labels = batch['labels'].cpu().numpy()\n",
    "#             outputs = model(**inputs)\n",
    "#             preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "#             # Apply threshold for multi-label classification\n",
    "#             preds = (preds > threshold).astype(int)\n",
    "#             all_preds.extend(preds)\n",
    "#             all_labels.extend(labels)\n",
    "\n",
    "#     return np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Training Loss: 0.1104\n",
      "Epoch 2/3, Training Loss: 0.0798\n",
      "Epoch 3/3, Training Loss: 0.0603\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  Service Issue       0.82      0.84      0.83       392\n",
      "   Food Options       0.62      0.51      0.56       278\n",
      "   Food Quality       0.81      0.86      0.83       465\n",
      "     Atmosphere       0.65      0.59      0.62       103\n",
      "Value for Money       0.74      0.51      0.60       184\n",
      "        Hygiene       0.69      0.62      0.65        58\n",
      "Positive Review       0.82      0.44      0.57       160\n",
      "\n",
      "      micro avg       0.76      0.69      0.73      1640\n",
      "      macro avg       0.74      0.63      0.67      1640\n",
      "   weighted avg       0.76      0.69      0.72      1640\n",
      "    samples avg       0.76      0.72      0.71      1640\n",
      "\n",
      "Accuracy: 0.375743162901308\n",
      "F1 Score (Micro): 0.7262247838616714\n",
      "F1 Score (Macro): 0.6687380966557391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# # Evaluation and metrics\n",
    "# preds, labels = evaluate(model, test_loader, threshold=0.5)\n",
    "# predicted_labels = (preds > 0.5).astype(int)\n",
    "# print(classification_report(labels, predicted_labels, target_names=['Service Issue', 'Food Options', 'Food Quality', 'Atmosphere', 'Value for Money', 'Hygiene', 'Positive Review']))\n",
    "# print(\"Accuracy:\", accuracy_score(labels, predicted_labels))\n",
    "# print(\"F1 Score (Micro):\", f1_score(labels, predicted_labels, average='micro'))\n",
    "# print(\"F1 Score (Macro):\", f1_score(labels, predicted_labels, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_labels = ['Service Issue', \"Food Quality\", \"Atmosphere\", \"Value for Money\", \"Hygiene\",\"Food Options\",\"Positive Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8. Evaluation Function with Adjustable Threshold\n",
    "# def evaluate(model, test_loader):\n",
    "#     model.eval()\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch in test_loader:\n",
    "#             inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "#             labels = batch['labels'].cpu().numpy()\n",
    "#             outputs = model(**inputs)\n",
    "#             preds = torch.sigmoid(outputs.logits).cpu().numpy()  # Get probabilities\n",
    "\n",
    "#             # Initialize lists for predicted categories and their probabilities\n",
    "#             predicted_categories = []\n",
    "#             probabilities_list = []\n",
    "\n",
    "#             # Apply Threshold Logic\n",
    "#             for pred in preds:\n",
    "#                 predicted_category = []\n",
    "#                 current_probabilities = []\n",
    "\n",
    "#                 for label, score in zip(category_labels, pred):\n",
    "#                     if score > 0.75:\n",
    "#                         predicted_category.append(label)\n",
    "#                         current_probabilities.append(score)\n",
    "\n",
    "#                 # If no categories were found with scores > 0.75, check for scores between 0.2 and 0.75\n",
    "#                 if not predicted_category:\n",
    "#                     max_score = -1\n",
    "#                     max_label = None\n",
    "#                     positive_review_score = pred[category_labels.index(\"Positive Review\")] if \"Positive Review\" in category_labels else 0\n",
    "\n",
    "#                     for label, score in zip(category_labels, pred):\n",
    "#                         if 0.2 <= score < 0.75:\n",
    "#                             if score > max_score:\n",
    "#                                 max_score = score\n",
    "#                                 max_label = label\n",
    "                    \n",
    "#                     # Prioritize \"Positive Review\" if its score is the highest\n",
    "#                     if positive_review_score > max_score:\n",
    "#                         predicted_category = [\"Positive Review\"]\n",
    "#                         current_probabilities = [positive_review_score]\n",
    "#                     elif max_label is not None:\n",
    "#                         predicted_category.append(max_label)\n",
    "#                         current_probabilities.append(max_score)\n",
    "\n",
    "#                 # If no categories were predicted, assign \"Positive Review\" with its probability\n",
    "#                 if not predicted_category:\n",
    "#                     predicted_category = [\"Positive Review\"]\n",
    "#                     current_probabilities = [positive_review_score]  # Use the actual probability for \"Positive Review\"\n",
    "\n",
    "#                 # Store results\n",
    "#                 predicted_categories.append(predicted_category)\n",
    "#                 probabilities_list.append(current_probabilities)\n",
    "\n",
    "#             all_preds.extend(predicted_categories)\n",
    "#             all_labels.extend(labels)\n",
    "\n",
    "#     return np.array(all_preds), np.array(all_labels), np.array(probabilities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].cpu().numpy()  # True labels\n",
    "            outputs = model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).cpu().numpy()  # Get probabilities\n",
    "            \n",
    "            # Initialize predictions\n",
    "            binary_preds = np.zeros((preds.shape[0], preds.shape[1]))\n",
    "\n",
    "            # Process predictions\n",
    "            for idx, prob in enumerate(preds):\n",
    "                predicted_categories = []\n",
    "                probabilities = []\n",
    "\n",
    "                # Step 1: Check for categories with probability > 0.75\n",
    "                for i, score in enumerate(prob):\n",
    "                    if score > 0.75:\n",
    "                        predicted_categories.append(category_labels[i])\n",
    "                        probabilities.append(score)\n",
    "\n",
    "                # Step 2: If no categories above 0.75, check for max probability in range 0.2-0.75\n",
    "                if not predicted_categories:\n",
    "                    max_prob = 0.0\n",
    "                    max_category = None\n",
    "                    for i, score in enumerate(prob):\n",
    "                        if 0.2 <= score < 0.75 and score > max_prob:\n",
    "                            max_prob = score\n",
    "                            max_category = category_labels[i]\n",
    "\n",
    "                    if max_category:\n",
    "                        predicted_categories.append(max_category)\n",
    "                        probabilities.append(max_prob)\n",
    "                    else:\n",
    "                        # Step 3: Assign positive review with its probability if all are below 0.2\n",
    "                        positive_review_prob = prob[category_labels.index(\"Positive Review\")]\n",
    "                        predicted_categories.append(\"Positive Review\")\n",
    "                        probabilities.append(positive_review_prob)\n",
    "\n",
    "                # Convert the predicted categories to binary format\n",
    "                for category in category_labels:\n",
    "                    if category in predicted_categories:\n",
    "                        binary_preds[idx, category_labels.index(category)] = 1\n",
    "\n",
    "            all_preds.append(binary_preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    # Convert lists to arrays\n",
    "    return np.vstack(all_preds), np.vstack(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Usage of the Evaluate Function\n",
    "predicted_labels, true_labels = evaluate(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of true labels: 841\n",
      "Length of predicted labels: 841\n"
     ]
    }
   ],
   "source": [
    "# Check the lengths\n",
    "print(\"Length of true labels:\", true_labels.shape[0])\n",
    "print(\"Length of predicted labels:\", predicted_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  Service Issue       0.89      0.76      0.82       392\n",
      "   Food Quality       0.68      0.27      0.39       278\n",
      "     Atmosphere       0.86      0.79      0.82       465\n",
      "Value for Money       0.78      0.50      0.61       103\n",
      "        Hygiene       0.79      0.46      0.58       184\n",
      "   Food Options       0.83      0.50      0.62        58\n",
      "Positive Review       0.80      0.42      0.56       160\n",
      "\n",
      "      micro avg       0.83      0.59      0.69      1640\n",
      "      macro avg       0.80      0.53      0.63      1640\n",
      "   weighted avg       0.81      0.59      0.67      1640\n",
      "    samples avg       0.83      0.65      0.69      1640\n",
      "\n",
      "Accuracy: 0.38882282996432815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate the classification report\n",
    "predicted_labels_binary = (predicted_labels > 0.5).astype(float)  # Binary representation based on probabilities\n",
    "\n",
    "# Generate the classification report\n",
    "print(classification_report(true_labels, predicted_labels_binary, target_names=category_labels))\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, predicted_labels_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The food was excellent and the service was great!\n",
      "Predicted Categories: ['Positive Review']\n",
      "Probabilities: [0.04665793 0.06056271 0.1329418  0.01477121 0.02874581 0.01821567\n",
      " 0.8305358 ]\n",
      "-----\n",
      "Review: I had a terrible experience with the hygiene of the restaurant.\n",
      "Predicted Categories: ['Atmosphere', 'Food Options']\n",
      "Probabilities: [0.59470195 0.33350614 0.9323903  0.35559288 0.15185976 0.9710812\n",
      " 0.05553968]\n",
      "-----\n",
      "Review: The ambiance was lovely, but the food options were limited.\n",
      "Predicted Categories: ['Food Quality']\n",
      "Probabilities: [0.02972805 0.7892593  0.28067574 0.05442077 0.25652114 0.00831567\n",
      " 0.3068922 ]\n",
      "-----\n",
      "Review: I would recommend this place for its value for money.\n",
      "Predicted Categories: ['Hygiene']\n",
      "Probabilities: [0.06078795 0.29377833 0.41276404 0.06392154 0.9379374  0.02645649\n",
      " 0.21547987]\n",
      "-----\n",
      "Review: Overall, a great place to dine with family.\n",
      "Predicted Categories: ['Positive Review']\n",
      "Probabilities: [0.01040346 0.10566269 0.04997773 0.07108229 0.05596929 0.02887302\n",
      " 0.85693985]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def classify_reviews(model, reviews, category_labels):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    # Tokenize the reviews (ensure you have a tokenizer defined)\n",
    "    tokenized_reviews = tokenizer(reviews, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_reviews)\n",
    "        preds = torch.sigmoid(outputs.logits).cpu().numpy()  # Get probabilities\n",
    "\n",
    "        for prob in preds:\n",
    "            predicted_categories = []\n",
    "            probabilities = []\n",
    "\n",
    "            # Step 1: Check for categories with probability > 0.75\n",
    "            for i, score in enumerate(prob):\n",
    "                if score > 0.75:\n",
    "                    predicted_categories.append(category_labels[i])\n",
    "                    probabilities.append(score)\n",
    "\n",
    "            # Step 2: If no categories above 0.75, check for max probability in range 0.2-0.75\n",
    "            if not predicted_categories:\n",
    "                max_prob = 0.0\n",
    "                max_category = None\n",
    "                for i, score in enumerate(prob):\n",
    "                    if 0.2 <= score < 0.75 and score > max_prob:\n",
    "                        max_prob = score\n",
    "                        max_category = category_labels[i]\n",
    "\n",
    "                if max_category:\n",
    "                    predicted_categories.append(max_category)\n",
    "                    probabilities.append(max_prob)\n",
    "                else:\n",
    "                    # Step 3: Assign positive review with its probability if all are below 0.2\n",
    "                    positive_review_prob = prob[category_labels.index(\"Positive Review\")]\n",
    "                    predicted_categories.append(\"Positive Review\")\n",
    "                    probabilities.append(positive_review_prob)\n",
    "\n",
    "            all_preds.append(predicted_categories)\n",
    "            all_probs.append(prob)\n",
    "\n",
    "    return all_preds, all_probs\n",
    "\n",
    "# Sample usage\n",
    "sample_reviews = [\n",
    "    \"The food was excellent and the service was great!\",\n",
    "    \"I had a terrible experience with the hygiene of the restaurant.\",\n",
    "    \"The ambiance was lovely, but the food options were limited.\",\n",
    "    \"I would recommend this place for its value for money.\",\n",
    "    \"Overall, a great place to dine with family.\"\n",
    "]\n",
    "\n",
    "predicted_categories, predicted_probabilities = classify_reviews(model, sample_reviews, category_labels)\n",
    "\n",
    "# Display results\n",
    "for review, categories, probs in zip(sample_reviews, predicted_categories, predicted_probabilities):\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted Categories: {categories}\")\n",
    "    print(f\"Probabilities: {probs}\")\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The food was excellent and the service was great!\n",
      "Predicted Categories: ['Positive Review']\n",
      "Probabilities: [0.83053577]\n",
      "-----\n",
      "Review: I had a terrible experience with the hygiene of the restaurant.\n",
      "Predicted Categories: ['Service Issue', 'Atmosphere', 'Food Options']\n",
      "Probabilities: [0.5947018, 0.93239015, 0.9710811]\n",
      "-----\n",
      "Review: The ambiance was lovely, but the food options were limited.\n",
      "Predicted Categories: ['Food Quality']\n",
      "Probabilities: [0.78925955]\n",
      "-----\n",
      "Review: I would recommend this place for its value for money.\n",
      "Predicted Categories: ['Hygiene']\n",
      "Probabilities: [0.9379374]\n",
      "-----\n",
      "Review: Overall, a great place to dine with family.\n",
      "Predicted Categories: ['Positive Review']\n",
      "Probabilities: [0.85693985]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "def classify_reviews(model, reviews, category_labels, threshold=0.5):\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for review in reviews:\n",
    "            # Prepare the input for the model\n",
    "            inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            # Get predictions from the model\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.sigmoid(outputs.logits).cpu().numpy()[0]  # Get probabilities\n",
    "            \n",
    "            predicted_categories = []\n",
    "            probabilities = []\n",
    "\n",
    "            # Check for categories with probability > 0.5\n",
    "            for i, score in enumerate(probs):\n",
    "                if score > threshold:\n",
    "                    predicted_categories.append(category_labels[i])\n",
    "                    probabilities.append(score)\n",
    "\n",
    "            # If no categories were predicted above the threshold, handle that case\n",
    "            if not predicted_categories:\n",
    "                # If no category has a score above the threshold, consider it as \"No Category\"\n",
    "                predicted_categories.append(\"No Category\")\n",
    "                probabilities.append(0.0)  # Assign a default for no category\n",
    "\n",
    "            results.append({\n",
    "                \"review\": review,\n",
    "                \"predicted_categories\": predicted_categories,\n",
    "                \"probabilities\": probabilities\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Sample reviews to classify\n",
    "sample_reviews = [\n",
    "    \"The food was excellent and the service was great!\",\n",
    "    \"I had a terrible experience with the hygiene of the restaurant.\",\n",
    "    \"The ambiance was lovely, but the food options were limited.\",\n",
    "    \"I would recommend this place for its value for money.\",\n",
    "    \"Overall, a great place to dine with family.\"\n",
    "]\n",
    "\n",
    "# Classify the sample reviews\n",
    "classified_results = classify_reviews(model, sample_reviews, category_labels)\n",
    "\n",
    "# Display the classification results\n",
    "for result in classified_results:\n",
    "    print(f\"Review: {result['review']}\")\n",
    "    print(f\"Predicted Categories: {result['predicted_categories']}\")\n",
    "    print(f\"Probabilities: {result['probabilities']}\")\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a directory to save the model and tokenizer\n",
    "model_save_path = 'r'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f'Model and tokenizer saved to {model_save_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
