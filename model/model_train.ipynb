{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YgbivjSrdGSQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "# from bertopic import BERTopic\n",
    "\n",
    "# import gensim\n",
    "# from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "! pip install numpy\n",
    "! pip install pandas\n",
    "! pip install nltk\n",
    "! pip install matplotlib\n",
    "! pip install sentence_transformers\n",
    "! pip install berTopic\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aOIcYVRSdARN"
   },
   "outputs": [],
   "source": [
    "categories_to_add = ['Service Issue', \"Food Quality\", \"Atmosphere\", \"Value for Money\", \"Hygiene\",\"Food Options\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "kqwEv4jlcuNI",
    "outputId": "843293cc-86f9-46ab-aaa7-5e5329c512e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Cleaned_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Is_Repeated</th>\n",
       "      <th>Frequency_Of_Complaint_Type</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "      <th>Review_Days</th>\n",
       "      <th>Response_Days</th>\n",
       "      <th>Others</th>\n",
       "      <th>Predicted_Category</th>\n",
       "      <th>Category_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stop eating at this place, I have visited bang...</td>\n",
       "      <td>stop eating place visited bangalores nd punes ...</td>\n",
       "      <td>pramod kumar</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Food Quality' 'Atmosphere' 'Hygiene']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Food 2/5\\nService 2/5\\nAmbience 2/5 …</td>\n",
       "      <td>food service ambience</td>\n",
       "      <td>abhinav deep</td>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>365.0</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>['Atmosphere' 'Service Issue' 'Food Quality' '...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Idiotic varieties for the price they have char...</td>\n",
       "      <td>idiotic varieties price charged varieties boil...</td>\n",
       "      <td>vijay nammi</td>\n",
       "      <td>Value for Money</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Food Options']</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I am posting this live now, this is one of the...</td>\n",
       "      <td>posting live one worst places dont visit pathe...</td>\n",
       "      <td>surya ajay</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>365.0</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>['Service Issue' 'Food Quality' 'Atmosphere']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We are pure vegetarians, I ordered veg biryani...</td>\n",
       "      <td>pure vegetarians ordered veg biryani swiggy go...</td>\n",
       "      <td>sai hithesh</td>\n",
       "      <td>Value for Money</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Food Quality']</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Review  \\\n",
       "0           0  Stop eating at this place, I have visited bang...   \n",
       "1           1              Food 2/5\\nService 2/5\\nAmbience 2/5 …   \n",
       "2           2  Idiotic varieties for the price they have char...   \n",
       "3           3  I am posting this live now, this is one of the...   \n",
       "4           4  We are pure vegetarians, I ordered veg biryani...   \n",
       "\n",
       "                                      Cleaned_Review  Cleaned_Name  \\\n",
       "0  stop eating place visited bangalores nd punes ...  pramod kumar   \n",
       "1                              food service ambience  abhinav deep   \n",
       "2  idiotic varieties price charged varieties boil...   vijay nammi   \n",
       "3  posting live one worst places dont visit pathe...    surya ajay   \n",
       "4  pure vegetarians ordered veg biryani swiggy go...   sai hithesh   \n",
       "\n",
       "          Category Severity  Is_Repeated Frequency_Of_Complaint_Type  \\\n",
       "0       Atmosphere     High        False                      Unique   \n",
       "1     Food Quality   Medium        False                      Unique   \n",
       "2  Value for Money     High        False                      Unique   \n",
       "3       Atmosphere     High        False                      Unique   \n",
       "4  Value for Money      Low        False                      Unique   \n",
       "\n",
       "      Urgency Customer_Satisfaction  Review_Days  Response_Days  Others  \\\n",
       "0      Urgent           No Response        180.0             -1       0   \n",
       "1  Non-Urgent     High Satisfaction        365.0            365       0   \n",
       "2      Urgent           No Response         30.0             -1       0   \n",
       "3      Urgent     High Satisfaction        365.0            365       0   \n",
       "4  Non-Urgent           No Response        180.0             -1       0   \n",
       "\n",
       "                                  Predicted_Category  Category_Label  \n",
       "0            ['Food Quality' 'Atmosphere' 'Hygiene']               0  \n",
       "1  ['Atmosphere' 'Service Issue' 'Food Quality' '...               2  \n",
       "2                                   ['Food Options']               5  \n",
       "3      ['Service Issue' 'Food Quality' 'Atmosphere']               0  \n",
       "4                                   ['Food Quality']               5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new_dataset.csv')\n",
    "df.drop(columns=categories_to_add,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FONPs9MydKrT"
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from datasets import Dataset\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define Labels for Classification\n",
    "# category_labels = ['Service Issue', 'Food Quality','Food Options',\n",
    "#                    'Atmosphere', 'Value for Money', 'Hygiene']\n",
    "\n",
    "# threshold = 0.5  # Adjust this value as needed\n",
    "\n",
    "# # Load Zero-Shot Classification Model\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)\n",
    "\n",
    "# # Convert DataFrame to Hugging Face Dataset\n",
    "# dataset = Dataset.from_pandas(combined_df)\n",
    "\n",
    "# # Function to Classify Each Review with Multi-Label Output\n",
    "# def classify_review_batch(batch):\n",
    "#     results = classifier(batch['Review'], candidate_labels=category_labels, multi_label=True)\n",
    "#     batch['Predicted_Category'] = [\n",
    "#         [label for label, score in zip(result['labels'], result['scores']) if score >= threshold]\n",
    "#         if any(score >= threshold for score in result['scores'])\n",
    "#         else [result['labels'][0]]  # Default to highest score if no category meets threshold\n",
    "#         for result in results\n",
    "#     ]\n",
    "#     return batch\n",
    "\n",
    "# # Apply Classification to the Dataset\n",
    "# dataset = dataset.map(classify_review_batch, batched=True)\n",
    "\n",
    "# # Convert back to DataFrame if needed\n",
    "# combined_df = dataset.to_pandas()\n",
    "# print(combined_df[['Review', 'Predicted_Category']].value_counts())\n",
    "# combined_df.to_csv('new_classified_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tO3CFsr5dTXT"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# categories_to_add = ['Service Issue', \"Food Quality\", \"Atmosphere\", \"Value for Money\", \"Hygiene\", \"Food Options\"]\n",
    "# mlb = MultiLabelBinarizer(classes=categories_to_add)\n",
    "# one_hot_encoded = mlb.fit_transform(df['Predicted_Category'])\n",
    "\n",
    "# # Create a DataFrame with the one-hot encoded values\n",
    "# one_hot_df = pd.DataFrame(one_hot_encoded, columns=mlb.classes_)\n",
    "\n",
    "# # Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "# final_df = pd.concat([df, one_hot_df], axis=1)\n",
    "\n",
    "# print(final_df['Predicted_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RedpjpAxeDSX"
   },
   "outputs": [],
   "source": [
    "# # Initialize the MultiLabelBinarizer\n",
    "# mlb = MultiLabelBinarizer(classes=categories_to_add)\n",
    "\n",
    "# # Fit and transform the data\n",
    "# one_hot_encoded = mlb.fit_transform(df['Predicted_Category'])\n",
    "\n",
    "# # Create a new DataFrame with one-hot encoded data\n",
    "# one_hot_df = pd.DataFrame(one_hot_encoded, columns=mlb.classes_)\n",
    "\n",
    "# # Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "# final_df = pd.concat([df, one_hot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CtKJXAbvekIl"
   },
   "outputs": [],
   "source": [
    "# Define categories to add\n",
    "categories_to_add = ['Service Issue', 'Food Quality', 'Atmosphere', 'Value for Money', 'Hygiene', 'Food Options']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vVAuF10ae4RL",
    "outputId": "59ad8065-a12a-438e-fc7a-2e25618598a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Food Quality' 'Atmosphere' 'Hygiene']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Predicted_Category'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "id": "kpoMyYdjfPIC",
    "outputId": "f688b7a9-3ade-4709-ebbc-b34f58c28447"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Cleaned_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Is_Repeated</th>\n",
       "      <th>Frequency_Of_Complaint_Type</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>Response_Days</th>\n",
       "      <th>Others</th>\n",
       "      <th>Predicted_Category</th>\n",
       "      <th>Category_Label</th>\n",
       "      <th>Service Issue</th>\n",
       "      <th>Food Quality</th>\n",
       "      <th>Atmosphere</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Hygiene</th>\n",
       "      <th>Food Options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stop eating at this place, I have visited bang...</td>\n",
       "      <td>stop eating place visited bangalores nd punes ...</td>\n",
       "      <td>pramod kumar</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Food Quality' 'Atmosphere' 'Hygiene']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Food 2/5\\nService 2/5\\nAmbience 2/5 …</td>\n",
       "      <td>food service ambience</td>\n",
       "      <td>abhinav deep</td>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>['Atmosphere' 'Service Issue' 'Food Quality' '...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Idiotic varieties for the price they have char...</td>\n",
       "      <td>idiotic varieties price charged varieties boil...</td>\n",
       "      <td>vijay nammi</td>\n",
       "      <td>Value for Money</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Food Options']</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I am posting this live now, this is one of the...</td>\n",
       "      <td>posting live one worst places dont visit pathe...</td>\n",
       "      <td>surya ajay</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>['Service Issue' 'Food Quality' 'Atmosphere']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We are pure vegetarians, I ordered veg biryani...</td>\n",
       "      <td>pure vegetarians ordered veg biryani swiggy go...</td>\n",
       "      <td>sai hithesh</td>\n",
       "      <td>Value for Money</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Food Quality']</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>4200</td>\n",
       "      <td>Place where food lovers can enjoy their food a...</td>\n",
       "      <td>place food lovers enjoy food apart dishes rest...</td>\n",
       "      <td>hemanth kumar pallapu</td>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Value for Money' 'Food Quality' 'Food Option...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>4201</td>\n",
       "      <td>Good place to visit with friends and family, t...</td>\n",
       "      <td>good place visit friends family customised foo...</td>\n",
       "      <td>abhinay maredugonda</td>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Value for Money' 'Atmosphere' 'Food Options'...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>4202</td>\n",
       "      <td>The food is very good, service is also good. B...</td>\n",
       "      <td>food good service also good compare service co...</td>\n",
       "      <td>devesh gupta</td>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Food Quality' 'Value for Money' 'Food Options']</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>4203</td>\n",
       "      <td>Nice place to hangout with a small team of upt...</td>\n",
       "      <td>nice place hangout small team upto members goo...</td>\n",
       "      <td>raja roy</td>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Value for Money' 'Atmosphere' 'Food Quality'...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>4204</td>\n",
       "      <td>Best place for foodies and who love grilled fo...</td>\n",
       "      <td>best place foodies love grilled food went fami...</td>\n",
       "      <td>udaya devarakonda</td>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Unique</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Value for Money' 'Food Options' 'Food Qualit...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4205 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                             Review  \\\n",
       "0              0  Stop eating at this place, I have visited bang...   \n",
       "1              1              Food 2/5\\nService 2/5\\nAmbience 2/5 …   \n",
       "2              2  Idiotic varieties for the price they have char...   \n",
       "3              3  I am posting this live now, this is one of the...   \n",
       "4              4  We are pure vegetarians, I ordered veg biryani...   \n",
       "...          ...                                                ...   \n",
       "4200        4200  Place where food lovers can enjoy their food a...   \n",
       "4201        4201  Good place to visit with friends and family, t...   \n",
       "4202        4202  The food is very good, service is also good. B...   \n",
       "4203        4203  Nice place to hangout with a small team of upt...   \n",
       "4204        4204  Best place for foodies and who love grilled fo...   \n",
       "\n",
       "                                         Cleaned_Review  \\\n",
       "0     stop eating place visited bangalores nd punes ...   \n",
       "1                                 food service ambience   \n",
       "2     idiotic varieties price charged varieties boil...   \n",
       "3     posting live one worst places dont visit pathe...   \n",
       "4     pure vegetarians ordered veg biryani swiggy go...   \n",
       "...                                                 ...   \n",
       "4200  place food lovers enjoy food apart dishes rest...   \n",
       "4201  good place visit friends family customised foo...   \n",
       "4202  food good service also good compare service co...   \n",
       "4203  nice place hangout small team upto members goo...   \n",
       "4204  best place foodies love grilled food went fami...   \n",
       "\n",
       "               Cleaned_Name         Category Severity  Is_Repeated  \\\n",
       "0              pramod kumar       Atmosphere     High        False   \n",
       "1              abhinav deep     Food Quality   Medium        False   \n",
       "2               vijay nammi  Value for Money     High        False   \n",
       "3                surya ajay       Atmosphere     High        False   \n",
       "4               sai hithesh  Value for Money      Low        False   \n",
       "...                     ...              ...      ...          ...   \n",
       "4200  hemanth kumar pallapu     Food Quality      Low        False   \n",
       "4201    abhinay maredugonda     Food Quality      Low        False   \n",
       "4202           devesh gupta     Food Quality      Low        False   \n",
       "4203               raja roy     Food Quality      Low        False   \n",
       "4204      udaya devarakonda     Food Quality      Low        False   \n",
       "\n",
       "     Frequency_Of_Complaint_Type     Urgency Customer_Satisfaction  ...  \\\n",
       "0                         Unique      Urgent           No Response  ...   \n",
       "1                         Unique  Non-Urgent     High Satisfaction  ...   \n",
       "2                         Unique      Urgent           No Response  ...   \n",
       "3                         Unique      Urgent     High Satisfaction  ...   \n",
       "4                         Unique  Non-Urgent           No Response  ...   \n",
       "...                          ...         ...                   ...  ...   \n",
       "4200                      Unique  Non-Urgent           No Response  ...   \n",
       "4201                      Unique  Non-Urgent           No Response  ...   \n",
       "4202                      Unique  Non-Urgent           No Response  ...   \n",
       "4203                      Unique  Non-Urgent           No Response  ...   \n",
       "4204                      Unique  Non-Urgent           No Response  ...   \n",
       "\n",
       "      Response_Days  Others  \\\n",
       "0                -1       0   \n",
       "1               365       0   \n",
       "2                -1       0   \n",
       "3               365       0   \n",
       "4                -1       0   \n",
       "...             ...     ...   \n",
       "4200             -1       0   \n",
       "4201             -1       0   \n",
       "4202             -1       0   \n",
       "4203             -1       0   \n",
       "4204             -1       0   \n",
       "\n",
       "                                     Predicted_Category Category_Label  \\\n",
       "0               ['Food Quality' 'Atmosphere' 'Hygiene']              0   \n",
       "1     ['Atmosphere' 'Service Issue' 'Food Quality' '...              2   \n",
       "2                                      ['Food Options']              5   \n",
       "3         ['Service Issue' 'Food Quality' 'Atmosphere']              0   \n",
       "4                                      ['Food Quality']              5   \n",
       "...                                                 ...            ...   \n",
       "4200  ['Value for Money' 'Food Quality' 'Food Option...              2   \n",
       "4201  ['Value for Money' 'Atmosphere' 'Food Options'...              2   \n",
       "4202  ['Food Quality' 'Value for Money' 'Food Options']              2   \n",
       "4203  ['Value for Money' 'Atmosphere' 'Food Quality'...              2   \n",
       "4204  ['Value for Money' 'Food Options' 'Food Qualit...              2   \n",
       "\n",
       "      Service Issue  Food Quality  Atmosphere  Value for Money  Hygiene  \\\n",
       "0                 0             1           1                0        1   \n",
       "1                 1             1           1                0        0   \n",
       "2                 0             0           0                0        0   \n",
       "3                 1             1           1                0        0   \n",
       "4                 0             1           0                0        0   \n",
       "...             ...           ...         ...              ...      ...   \n",
       "4200              0             1           1                1        0   \n",
       "4201              0             1           1                1        0   \n",
       "4202              0             1           0                1        0   \n",
       "4203              1             1           1                1        0   \n",
       "4204              0             1           1                1        0   \n",
       "\n",
       "      Food Options  \n",
       "0                0  \n",
       "1                1  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "4200             1  \n",
       "4201             1  \n",
       "4202             1  \n",
       "4203             1  \n",
       "4204             1  \n",
       "\n",
       "[4205 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: '['Food Quality' 'Atmosphere' 'Hygiene']' i want to convert this into individual columns of categories like ['Service Issue', 'Food Quality', 'Atmosphere', 'Value for Money', 'Hygiene', 'Food Options'] and put the binary values where the column is present in the givien string\n",
    "\n",
    "def create_binary_columns(row):\n",
    "  \"\"\"Creates binary columns for each category based on the presence of the category in the string.\"\"\"\n",
    "  categories_found = row['Predicted_Category']\n",
    "  for category in categories_to_add:\n",
    "    if category in categories_found:\n",
    "      row[category] = 1\n",
    "    else:\n",
    "      row[category] = 0\n",
    "  return row\n",
    "\n",
    "# Apply the function to create the new columns\n",
    "df = df.apply(create_binary_columns, axis=1)\n",
    "\n",
    "# Drop the original 'Predicted_Category' column if needed\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "wp95j8FCf7UQ",
    "outputId": "8e5cdea1-2515-48cb-b9e5-862925a1fb34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "211/211 [==============================] - 1010s 5s/step - loss: 0.5499 - accuracy: 0.4893 - val_loss: 0.4715 - val_accuracy: 0.6005\n",
      "Epoch 2/4\n",
      "211/211 [==============================] - 1084s 5s/step - loss: 0.4551 - accuracy: 0.6052 - val_loss: 0.4437 - val_accuracy: 0.5910\n",
      "Epoch 3/4\n",
      "211/211 [==============================] - 1014s 5s/step - loss: 0.3862 - accuracy: 0.6189 - val_loss: 0.4465 - val_accuracy: 0.5589\n",
      "Epoch 4/4\n",
      "211/211 [==============================] - 945s 4s/step - loss: 0.3190 - accuracy: 0.6356 - val_loss: 0.4576 - val_accuracy: 0.5482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['Cleaned_Review'], df[categories_to_add], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels))\n",
    "\n",
    "! pip install transformers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# ... (rest of the code remains the same)\n",
    "\n",
    "# Load BERT model\n",
    "# Change num_labels to match the number of categories\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(categories_to_add))\n",
    "\n",
    "# Compile the model\n",
    "# Change loss to BinaryCrossentropy for multi-label classification\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), # Changed loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset.shuffle(100).batch(16), epochs=4, batch_size=16,\n",
    "                    validation_data=test_dataset.batch(16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaFXo0JVj356",
    "outputId": "78a513ac-8afd-4f03-e4fd-26dfc866e67c"
   },
   "outputs": [],
   "source": [
    "# prompt: want to increase the accuracy of code present in above cell\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# ... (rest of the code remains the same)\n",
    "\n",
    "# Load BERT model\n",
    "# Change num_labels to match the number of categories\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(categories_to_add))\n",
    "\n",
    "# Compile the model\n",
    "# Change loss to BinaryCrossentropy for multi-label classification\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), # Changed loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset.shuffle(100).batch(16), epochs=5, batch_size=16,\n",
    "                    validation_data=test_dataset.batch(16))\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(test_dataset.batch(16))\n",
    "predicted_labels = (tf.nn.sigmoid(predictions.logits) > 0.5).numpy().astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print(classification_report(test_labels, predicted_labels, target_names=categories_to_add))\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, predicted_labels))\n",
    "print(\"F1 Score (Micro):\", f1_score(test_labels, predicted_labels, average='micro'))\n",
    "print(\"F1 Score (Macro):\", f1_score(test_labels, predicted_labels, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1e6kLy9gIY7",
    "outputId": "e17f2c80-eb4c-47a5-ccbb-81402ca8eaed"
   },
   "outputs": [],
   "source": [
    "# prompt: as well as i want predict multi label for a specific unseen review\n",
    "\n",
    "def predict_multi_label(review_text):\n",
    "  \"\"\"Predicts the multi-label categories for a given review text.\"\"\"\n",
    "\n",
    "  # Tokenize the review text\n",
    "  inputs = tokenizer(review_text, truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "  # Make predictions using the trained model\n",
    "  outputs = model(inputs)\n",
    "  predictions = tf.nn.sigmoid(outputs.logits).numpy()\n",
    "\n",
    "  # Define a threshold for classifying labels\n",
    "  threshold = 0.5  # Adjust as needed\n",
    "  \n",
    "  # Get the predicted labels based on the threshold\n",
    "  predicted_labels = [label for i, label in enumerate(categories_to_add) if predictions[0][i] >= threshold]\n",
    "  if predict_multi_label:\n",
    "    return predicted_labels\n",
    "  else:\n",
    "    return max(predicted_labels, key=lambda x: predictions[0][categories_to_add.index(x)])\n",
    "\n",
    "# Example usage:\n",
    "unseen_review = \"There is no cleanliness and staff was not good at all\"\n",
    "predicted_categories = predict_multi_label(unseen_review)\n",
    "print(f\"Predicted categories for the review: {predicted_categories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gv59gVK_ju4n"
   },
   "outputs": [],
   "source": [
    "# prompt: how to use this folder for further predictions in another location\n",
    "\n",
    "# ... (Your existing code)\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained('/content/drive/MyDrive/your_model_folder') # Change to your desired folder\n",
    "tokenizer.save_pretrained('/content/drive/MyDrive/your_model_folder')\n",
    "\n",
    "# Function to load and use the model for predictions in another location\n",
    "def load_and_predict(review_text, model_path='/content/drive/MyDrive/your_model_folder'):\n",
    "  \"\"\"Loads a saved model and tokenizer from Google Drive and makes predictions.\"\"\"\n",
    "\n",
    "  loaded_model = TFBertForSequenceClassification.from_pretrained(model_path)\n",
    "  loaded_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "  # Tokenize the review text\n",
    "  inputs = loaded_tokenizer(review_text, truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "  # Make predictions using the loaded model\n",
    "  outputs = loaded_model(inputs)\n",
    "  predictions = tf.nn.sigmoid(outputs.logits).numpy()\n",
    "\n",
    "  # Define a threshold for classifying labels\n",
    "  threshold = 0.7  # Adjust as needed\n",
    "\n",
    "  # Get the predicted labels based on the threshold\n",
    "  predicted_labels = [label for i, label in enumerate(categories_to_add) if predictions[0][i] >= threshold]\n",
    "\n",
    "  return predicted_labels\n",
    "\n",
    "\n",
    "# Example usage in another location:\n",
    "# (Assume you've mounted Google Drive in the new location)\n",
    "\n",
    "# new_review = \"The food was delicious, but the service was slow.\"\n",
    "# predicted_categories = load_and_predict(new_review)\n",
    "# print(f\"Predicted categories for the new review: {predicted_categories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "NWVBRMqgEAdP",
    "outputId": "fbd2f9f2-d179-4cdd-cf4b-ae6a258c214d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
